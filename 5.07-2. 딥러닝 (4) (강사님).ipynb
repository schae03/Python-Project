{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d797f2b8-3a38-42fd-a569-284348746756",
   "metadata": {},
   "source": [
    "# 딥러닝 (4)\n",
    "## 오차역전파(Backpropagation)\n",
    "오차역전파는 인공 신경망(Artificial Neural Network)을 학습시키는 데 사용되는 핵심 알고리즘입니다. 신경망의 예측 결과와 실제 정답 사이의 오차(손실, Loss)를 계산하고, 이 오차를 신경망의 출력층부터 입력층 방향으로 거꾸로 전파시키면서 각 가중치(Weight)와 편향(Bias)이 오차에 얼마나 기여했는지를 계산합니다. 이렇게 계산된 기여도(기울기, Gradient)를 사용하여 가중치와 편향을 업데이트함으로써 신경망이 점차 정확한 예측을 할 수 있도록 만듭니다.\n",
    "\n",
    "쉽게 말해, \"네트워크가 왜 틀렸는지를 파악하고, 그 틀린 정도를 각 부품(가중치, 편향)의 책임으로 나누어 할당한 뒤, 각 부품을 오차를 줄이는 방향으로 조금씩 수정하는 과정\"이라고 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b04465-78c8-4a84-9f20-5c7724d0b125",
   "metadata": {},
   "source": [
    "* 곱셈 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1958723b-f6f4-4004-b104-b8f4bdb1f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x * y\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = self.y * dout\n",
    "        dy = self.x * dout\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a186e30-66ff-4f5c-be58-8d6a694df7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "mul_apple = MulLayer()\n",
    "mul_tax = MulLayer()\n",
    "\n",
    "apple_price = mul_apple.forward(apple, apple_num)\n",
    "apple_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c31057bc-b5ae-452b-90e0-fb118120dc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul_apple.x, mul_apple.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "633ec695-45f8-4dcf-bd03-9eadae7bf261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220.00000000000003"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = mul_tax.forward(apple_price, tax)\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "915ab79e-5d40-4c37-856b-eb51219d1709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1, 200)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dout = 1\n",
    "dapple_price, dtax = mul_tax.backward(dout)\n",
    "dapple_price, dtax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "769573ec-2cb8-4da3-8fd9-f04c3ce7a423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.2, 110.00000000000001)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dapple, dapple_num = mul_apple.backward(dapple_price)\n",
    "dapple, dapple_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf52572-21e2-40b1-a3b5-4f30ec175014",
   "metadata": {},
   "source": [
    "* 덧셈 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58b53d12-f967-4e28-8272-477b06cc9499",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71154438-f141-4447-9583-a3b56afe5fcc",
   "metadata": {},
   "source": [
    "* Relu 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7ae9217-2f44-4b8e-ac97-bc5b6ac623c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336e49d4-eba6-41bf-b81b-bc6d134d2408",
   "metadata": {},
   "source": [
    "* Sigmoid 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49b463f1-3c42-4c87-8471-919172b01829",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out = 1 / (1 + np.exp(-x))\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1 - self.out) * self.out\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb0b8f88-b710-4313-9d83-3ad95f8c40cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(p, r):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(r * np.log(p + delta))\n",
    "\n",
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    for idx in np.ndindex(x.shape):\n",
    "        tmp_val = x[idx]\n",
    "        \n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "\n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val\n",
    "    \n",
    "    return grad\n",
    "\n",
    "def softmax(x):\n",
    "    if x.ndim == 1:\n",
    "        c = np.max(x)\n",
    "        exp_a = np.exp(x-c)\n",
    "        sum_exp_a = np.sum(exp_a)\n",
    "        y = exp_a / sum_exp_a\n",
    "        return y\n",
    "    elif x.ndim == 2:\n",
    "        c = np.max(x, axis = 1).reshape(-1, 1)\n",
    "        exp_a = np.exp(x - c)\n",
    "        sum_exp_a = np.sum(exp_a, axis = 1).reshape(-1, 1)\n",
    "        y = exp_a / sum_exp_a\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa1838c-d002-4a83-a374-52044716960f",
   "metadata": {},
   "source": [
    "* Softmax 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f73112c-10e8-46a4-866c-eb93830118cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fcecf7-f836-4d2d-8353-9efa47f89707",
   "metadata": {},
   "source": [
    "* Affine 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "770f6850-9212-419f-83b3-c1197de1677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = x @ self.w + self.b\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout @ self.w.T\n",
    "        self.dw = self.x.T @ dout\n",
    "        self.db = np.sum(dout, axis = 0)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862403f5-4281-4d0b-90aa-da5f6c4c6e19",
   "metadata": {},
   "source": [
    "* 오차역전파 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68070b0b-c323-47cb-b0e5-d696cdda93bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, I, H, O):\n",
    "        self.params = {}\n",
    "        self.params['w1'] = np.random.randn(I, H)\n",
    "        self.params['b1'] = np.random.randn(H)\n",
    "        self.params['w2'] = np.random.randn(H, O)\n",
    "        self.params['b2'] = np.random.randn(O)\n",
    "\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.params['w1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['w2'], self.params['b2'])\n",
    "        self.last_layer = SoftmaxLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for i in self.layers.values():\n",
    "            x = i.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis = 1)\n",
    "        accuracy = np.sum(y == t) / x.shape[0]\n",
    "        return accuracy\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_w = lambda w : self.loss(x, t)\n",
    "        grads = {}\n",
    "        grads['w1'] = numerical_gradient(loss_w, self.params['w1'])\n",
    "        grads['b1'] = numerical_gradient(loss_w, self.params['b1'])\n",
    "        grads['w2'] = numerical_gradient(loss_w, self.params['w2'])\n",
    "        grads['b2'] = numerical_gradient(loss_w, self.params['b2'])\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        self.loss(x, t)\n",
    "\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "\n",
    "        for i in layers:\n",
    "            dout = i.backward(dout)\n",
    "\n",
    "        grads = {}\n",
    "        grads['w1'] = self.layers['Affine1'].dw\n",
    "        grads['b1'] = self.layers['Affine1'].db\n",
    "        grads['w2'] = self.layers['Affine2'].dw\n",
    "        grads['b2'] = self.layers['Affine2'].db\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b666773-a505-4958-b2d4-019cb028a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"Data/mnist.dat\", 'rb')\n",
    "train, test = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "train_x, train_y = train\n",
    "test_x, test_y = test\n",
    "\n",
    "train_scaled = train_x.reshape(-1, 784) / 255\n",
    "test_scaled = test_x.reshape(-1, 784) / 255\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "train_y = encoder.fit_transform(train_y.reshape(-1, 1)).toarray()\n",
    "test_y = encoder.fit_transform(test_y.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5072f3fe-0f25-4256-b604-28ac454c3202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d9f30b-0ce9-446a-bd4c-1ab03f4d7d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████                                                                | 1697/10000 [06:37<35:56,  3.85it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "net = TwoLayerNet(784, 500, 10)\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for i in tqdm(range(10000)):\n",
    "    mask = np.random.choice(60000, 1000)\n",
    "    x_batch = train_scaled[mask]\n",
    "    t_batch = train_y[mask]\n",
    "\n",
    "    grad = net.gradient(x_batch, t_batch)\n",
    "\n",
    "    for key in ('w1', 'b1', 'w2', 'b2'):\n",
    "        net.params[key] -= grad[key] * 0.1\n",
    "\n",
    "    loss = net.loss(x_batch, t_batch)\n",
    "    test_loss = net.loss(test_scaled, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48642e5-618c-48e3-999d-14f52531b518",
   "metadata": {},
   "source": [
    "## 연습문제\n",
    "1. 어떤 상품 3개의 가격이 각각 1500원이라고 할 때, 총 가격을 계산하기 위해 곱셈 계층을 사용하려 합니다.\n",
    "* 순전파: 입력 x = 1500, y = 3일 때, MulLayer의 순전파 결과 out은 얼마인가요? 계산 과정을 보이세요.\n",
    "* 역전파: 최종 계산된 총 가격에 대한 손실의 미분 값(상류 미분)이 dout = 0.1이라고 할 때, MulLayer의 역전파를 통해 입력 x와 y 각각에 대한 미분 값 dx와 dy는 얼마인가요? 계산 과정을 보이세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33f269da-f53a-46c6-b5f2-ec9d22298954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.30000000000000004, 150.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 1500\n",
    "y = 3\n",
    "\n",
    "dout = 0.1\n",
    "\n",
    "dx = dout * y\n",
    "dy = dout * x\n",
    "\n",
    "dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc1dd45-133d-4d05-9472-b1f5ef44d7aa",
   "metadata": {},
   "source": [
    "2. 사과 가격 2000원과 바나나 가격 1500원을 더하여 총 가격을 계산하려 합니다.\n",
    "* 순전파: 입력 x = 2000, y = 1500일 때, AddLayer의 순전파 결과 out은 얼마인가요? 계산 과정을 보이세요.\n",
    "* 역전파: 최종 계산된 총 가격에 대한 손실의 미분 값(상류 미분)이 dout = 0.5라고 할 때, AddLayer의 역전파를 통해 입력 x와 y 각각에 대한 미분 값 dx와 dy는 얼마인가요? 계산 과정을 보이세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f228c3f-1292-443e-851f-beaeb190a320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 2000\n",
    "y = 1500\n",
    "out = x + y\n",
    "\n",
    "dout = 0.5\n",
    "\n",
    "dx = dout * 1\n",
    "dy = dout * 1\n",
    "\n",
    "dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb624382-67de-4206-9cc3-d5abac162398",
   "metadata": {},
   "source": [
    "3. 사과 5개 (가격 100원/개)와 오렌지 7개 (가격 150원/개)를 구매하고, 여기에 세금 20%을 적용한 최종 가격을 계산하는 상황을 가정합니다.\n",
    "* 최종 가격 final_price에 대한 손실의 미분 값(상류 미분)이 dout = 1이라고 할 때, 오차역전파 과정을 따라가며 각 입력 값(사과 가격, 사과 개수, 오렌지 가격, 오렌지 개수, 세금)에 대한 최종 손실의 미분 값을 구하는 과정을 설명하고 계산해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "deb948fd-1dcc-4735-b89a-0084427a4865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.0, 120.0, 8.4, 180.0, 1550)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 5\n",
    "\n",
    "orange = 150\n",
    "orange_num = 7\n",
    "\n",
    "tax = 1.2      # 세금 20%\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_layer = AddLayer()           # 사과, 오렌지 더해주는 덧셈계층\n",
    "mul_tax_layer = MulLayer()         # 세금 곱해주는 곱셈계층 \n",
    "\n",
    "# 순전파\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num)\n",
    "all_price = add_layer.forward(apple_price, orange_price)\n",
    "price = mul_tax_layer.forward(all_price, tax)\n",
    "\n",
    "# 각각의 최송 손실의 미분값 구하라 = 역전파\n",
    "dall_price, dtax = mul_tax_layer.backward(1)\n",
    "dapple_price, dorange_price = add_layer.backward(dall_price)   # 사과가격을 미분, 오렌지가격을 미분\n",
    "\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price)\n",
    "\n",
    "dapple, dapple_num, dorange, dorange_num, dtax "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57863a26-7aa1-47d2-91ff-9101e0ee734a",
   "metadata": {},
   "source": [
    "4. 입력 값 x = [-1, 0.5, -2, 3]이 ReLU 계층을 통과했다고 가정합니다. 순전파 결과 out을 계산하고, 상류 미분 dout = [0.2, 0.3, 0.1, 0.4]가 주어졌을 때, 역전파 결과 dx를 계산하세요. ReLU의 역전파 특징을 확인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46ae7e56-571e-40bc-9fb9-fac1c7b44496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.3, 0. , 0.4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([-1, 0.5, -2, 3])\n",
    "\n",
    "relu = Relu()\n",
    "relu.forward(x)\n",
    "\n",
    "dout = np.array([0.2, 0.3, 0.1, 0.4])\n",
    "relu.backward(dout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e05b8a-425b-471d-a5eb-049a55c564ed",
   "metadata": {},
   "source": [
    "5. Sigmoid 계층의 순전파 결과 self.out = 0.7이라고 가정합니다. 상류 미분 dout = 0.5가 주어졌을 때, 역전파 결과 dx를 계산하세요. Sigmoid 함수의 미분 공식을 이용하여 설명해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d161c7e4-6e28-47d7-923e-1f3b4bd7654a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10500000000000001"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dout = 0.5\n",
    "dx = dout * 0.7 * (1 - 0.7)         # 시그모이드의 역전파... dx = dout * self.out * (1 - self.out)\n",
    "dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f98fc-e073-4b13-ad5c-f8640d2414d1",
   "metadata": {},
   "source": [
    "6. 입력 x = [1.0, 0.5] (shape (1, 2)), 가중치 행렬 W = [[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]] (shape (2, 3)), 편향 벡터 b = [0.1, 0.2, 0.3] (shape (3,))이 주어졌을 때, Affine 계층의 순전파 결과 out (shape (1, 3))을 계산하세요. 행렬 곱셈과 덧셈 과정을 보이세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9689c650-fecd-4fde-a8e8-4807410df2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3 0.7 1.1]\n",
      "[0.3 0.7 1.1]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1.0, 0.5])\n",
    "W = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
    "b = np.array([0.1, 0.2, 0.3])\n",
    "print(x @ W + b)\n",
    "\n",
    "affine = Affine(W, b)\n",
    "print(affine.forward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7c0a23-a63c-4934-bf05-80c9cfd756b7",
   "metadata": {},
   "source": [
    "7. 어떤 분류 문제에서 신경망의 출력이 Softmax 함수를 거친 확률 값 y = [0.1, 0.2, 0.7]이고, 실제 정답(원-핫 인코딩)이 t = [0, 0, 1]이라고 가정합니다. SoftmaxWithLoss 계층의 역전파를 통해 손실에 대한 Softmax 입력 값의 미분 dx를 계산하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7369c949-25dd-4b27-9d99-f01c4451c082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1,  0.2, -0.3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([0.1, 0.2, 0.7])\n",
    "t = np.array([0, 0, 1])\n",
    "\n",
    "dx = (y - t) / 1       # 데이터가 하나밖에없으므로 1로 나눠줌 (batch size가 1)\n",
    "dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb315c75-1acf-4f71-809c-84cca36b5ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
